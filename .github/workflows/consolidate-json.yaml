# ============================================================================
# RQB JSON Consolidation Workflow
# ============================================================================
# Purpose: Consolidates JSON files from release assets into gh-pages:
#          1. RQB-images.json - Hierarchical structure for Raspberry Pi Imager
#          2. RQB-releases.json - Stream-based structure for website /latest/ page
#          3. RQB-images-all.json - All releases for development/testing
#
# Architecture:
#   Each release contains RQB-images.json as an asset with both standard and
#   A/B image entries (marked with "image_type" field).
#
#   This workflow fetches from release assets and builds:
#
#   RQB-images.json (Pi Imager):
#   - Top-level: Main stable, Beta, Development (integration branch)
#   - "RasQberry Development Images" folder: dev-featuresXX images
#   - "RasQberry A/B Boot Images" folder: All A/B images (main, beta, dev)
#   - Raspberry Pi OS (64-bit)
#
#   RQB-releases.json (Website):
#   - streams.stable: Latest main release (or placeholder if none)
#   - streams.beta: Latest beta release (or placeholder if none)
#   - streams.dev: Latest from development branch (or fallback to dev-featuresXX)
#
# Trigger:
#   - Automatically triggered after image builds complete
#   - Scheduled every 8 hours to detect deleted releases
#   - On release deletion events
#   - Can also be triggered manually for debugging
# ============================================================================

name: Consolidate RQB JSON files

on:
  # Scheduled: Run every 8 hours (0:00, 8:00, 16:00 UTC) to detect stale/deleted releases
  schedule:
    - cron: '0 */8 * * *'

  # Trigger on release deletion
  release:
    types: [deleted]

  workflow_dispatch:
    inputs:
      trigger_source:
        description: 'Source that triggered this workflow'
        required: false
        type: string
        default: 'manual'
      trigger_type:
        description: 'Type of release that triggered (main/beta/dev)'
        required: false
        type: string
        default: 'unknown'

permissions:
  contents: write
  actions: write

jobs:
  consolidate:
    name: Consolidate JSON from release assets
    runs-on: ubuntu-latest

    steps:
      - name: Checkout gh-pages
        uses: actions/checkout@v4
        with:
          ref: gh-pages
          fetch-depth: 0

      - name: Fetch RQB-images.json from release assets
        id: fetch
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "=== Consolidating RQB-images.json from release assets ==="
          echo "Triggered by: ${{ github.event.inputs.trigger_source || github.event_name }}"
          echo ""

          mkdir -p /tmp/release-json

          # Get all releases that have RQB-images.json as an asset
          echo "Querying GitHub Releases API..."

          gh api repos/${{ github.repository }}/releases --paginate \
            --jq '.[] | select(.assets[].name == "RQB-images.json") | {tag: .tag_name, published: .published_at, asset_url: (.assets[] | select(.name == "RQB-images.json") | .browser_download_url)}' \
            > /tmp/releases-with-json.jsonl

          echo ""
          echo "Found releases with RQB-images.json:"
          cat /tmp/releases-with-json.jsonl | jq -r '.tag' || echo "None found"
          echo ""

          # Download RQB-images.json from each release
          while IFS= read -r line; do
            tag=$(echo "$line" | jq -r '.tag')
            asset_url=$(echo "$line" | jq -r '.asset_url')
            published=$(echo "$line" | jq -r '.published')

            # Extract branch name from tag (remove trailing -YYYY-MM-DD-HHMMSS)
            branch=$(echo "$tag" | sed -E 's/-[0-9]{4}-[0-9]{2}-[0-9]{2}-[0-9]{6}$//')

            output="/tmp/release-json/${tag}.json"

            echo "Downloading: $tag (branch: $branch)"
            if curl -sL -f "$asset_url" -o "$output"; then
              # Add metadata to the JSON for processing
              jq --arg tag "$tag" --arg branch "$branch" --arg published "$published" \
                '. + {_release_tag: $tag, _branch: $branch, _published: $published}' \
                "$output" > "${output}.tmp" && mv "${output}.tmp" "$output"
              echo "  ✓ Downloaded RQB-images.json from $tag"
            else
              echo "  ⚠ Failed to download from $tag"
            fi
          done < /tmp/releases-with-json.jsonl

          echo ""
          echo "=== Downloaded release JSON files ==="
          ls -la /tmp/release-json/ || echo "No files fetched"

      - name: Fetch official Raspberry Pi OS metadata
        id: raspios
        run: |
          echo "Fetching official Raspberry Pi OS metadata..."

          # Fetch from official Raspberry Pi Imager JSON
          # This is the same source Pi Imager uses
          curl -s -f "https://downloads.raspberrypi.com/os_list_imagingutility_v3.json" -o /tmp/rpi-official.json

          if [ -f /tmp/rpi-official.json ]; then
            echo "✓ Fetched official Raspberry Pi OS list"
          else
            echo "⚠ Failed to fetch official list, will use fallback"
          fi

      - name: Merge JSON files
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          import os
          import re
          from pathlib import Path

          print("=== Merging RQB-images.json files into hierarchical structure ===")

          # Collect entries by category
          main_std = []      # Main stable standard images (top-level)
          beta_std = []      # Beta standard images (top-level)
          dev_std = []       # Development branch images (top-level)
          dev_all = []       # All dev-* branches (flat folder)
          ab_all = []        # All A/B images (flat folder)

          # Collect ALL releases for RQB-images-all.json
          all_releases = []  # All releases from all branches

          # Helper to extract timestamp from URL filename
          # URL format: .../rasqberry-branch-YYYY-MM-DD-HHMMSS.img.xz
          def extract_timestamp(url):
              if not url:
                  return None
              filename = url.split('/')[-1].replace('.img.xz', '').replace('-ab', '')
              # Match YYYY-MM-DD-HHMMSS or YYYY-MM-DD at end of filename
              match = re.search(r'(\d{4}-\d{2}-\d{2}(?:-\d{6})?)$', filename)
              return match.group(1) if match else None

          json_dir = Path("/tmp/release-json")

          # First pass: group releases by branch and keep only the latest per branch
          branch_releases = {}  # branch -> (published_date, tag, json_file)

          for json_file in json_dir.glob("*.json"):
              try:
                  with open(json_file, 'r') as f:
                      data = json.load(f)

                  branch = data.get('_branch', '')
                  published = data.get('_published', '')
                  tag = data.get('_release_tag', json_file.stem)

                  if not branch:
                      print(f"  ⚠ Skipping {json_file.name}: no branch metadata")
                      continue

                  # Keep only the latest release per branch
                  if branch not in branch_releases or published > branch_releases[branch][0]:
                      branch_releases[branch] = (published, tag, json_file)
                      print(f"Found: {tag} (branch: {branch}, published: {published})")

              except Exception as e:
                  print(f"  Error reading {json_file}: {e}")

          print(f"\n=== Latest release per branch ===")
          for branch, (published, tag, _) in sorted(branch_releases.items()):
              print(f"  {branch}: {tag}")

          # Collect ALL releases for RQB-images-all.json (not just latest per branch)
          print(f"\n=== Collecting ALL releases for RQB-images-all.json ===")
          for json_file in sorted(json_dir.glob("*.json"), reverse=True):
              try:
                  with open(json_file, 'r') as f:
                      data = json.load(f)

                  tag = data.get('_release_tag', json_file.stem)
                  branch = data.get('_branch', '')
                  published = data.get('_published', '')

                  for entry in data.get('os_list', []):
                      name = entry.get('name', '')
                      if 'RasQberry' not in name:
                          continue

                      # Create entry with release metadata
                      entry_with_meta = {k: v for k, v in entry.items()
                                         if k not in ('_release_tag', '_branch', '_published')}
                      entry_with_meta['_release_tag'] = tag
                      entry_with_meta['_branch'] = branch
                      entry_with_meta['_published'] = published
                      all_releases.append(entry_with_meta)

              except Exception as e:
                  print(f"  Error reading {json_file}: {e}")

          print(f"  Collected {len(all_releases)} total release entries")

          # Second pass: process only the latest release per branch
          for branch_name, (published, tag, json_file) in branch_releases.items():
              print(f"\nProcessing: {tag} (branch: {branch_name})")

              try:
                  with open(json_file, 'r') as f:
                      data = json.load(f)

                  for entry in data.get('os_list', []):
                      name = entry.get('name', '')
                      image_type = entry.get('image_type', 'standard')
                      url = entry.get('url', '')

                      # Only include RasQberry entries
                      if 'RasQberry' not in name:
                          continue

                      # Remove internal fields before adding to output
                      entry_clean = {k: v for k, v in entry.items()
                                     if k not in ('image_type', '_release_tag', '_branch', '_published')}

                      # Classify by BRANCH NAME for proper categorization
                      # Dev and AB images: include branch name AND full timestamp for Pi Imager
                      if image_type == 'ab' or 'A/B' in name:
                          # A/B images: include branch name + timestamp
                          timestamp = extract_timestamp(entry.get('url', ''))
                          if timestamp:
                              entry_clean['name'] = f"RasQberry Two A/B ({branch_name} {timestamp})"
                          else:
                              entry_clean['name'] = f"RasQberry Two A/B ({branch_name})"
                          entry_clean['description'] = f"A/B boot image from {branch_name}"
                          ab_all.append((published, branch_name, entry_clean))
                          print(f"  → A/B folder: {entry_clean['name']}")
                      elif branch_name == 'development':
                          # Development integration branch → top-level dev entry
                          entry_clean['name'] = "RasQberry Two Dev (64-bit)"
                          entry_clean['description'] = "Development integration branch with latest features"
                          dev_std.append((published, branch_name, entry_clean))
                          print(f"  → Top-level Dev: {entry_clean['name']}")
                      elif branch_name.startswith('dev'):
                          # Dev images: include branch name + timestamp
                          timestamp = extract_timestamp(entry.get('url', ''))
                          if timestamp:
                              entry_clean['name'] = f"RasQberry Two Dev ({branch_name} {timestamp})"
                          else:
                              entry_clean['name'] = f"RasQberry Two Dev ({branch_name})"
                          entry_clean['description'] = f"Development build from {branch_name}"
                          dev_all.append((published, branch_name, entry_clean))
                          print(f"  → Dev folder: {entry_clean['name']}")
                      elif branch_name == 'beta':
                          # Beta branch → top-level beta entry
                          entry_clean['name'] = "RasQberry Two Beta (64-bit)"
                          entry_clean['description'] = "Beta release with new features for testing"
                          beta_std.append((published, branch_name, entry_clean))
                          print(f"  → Top-level Beta: {entry_clean['name']}")
                      elif branch_name == 'main':
                          # Main branch: only stable if name doesn't contain "Dev"
                          if 'Dev' in name:
                              # Main has dev image - put in dev folder
                              entry_clean['name'] = f"RasQberry Two Dev ({branch_name})"
                              entry_clean['description'] = f"Development build from {branch_name}"
                              dev_std.append((published, branch_name, entry_clean))
                              print(f"  → Dev folder (main has dev): {entry_clean['name']}")
                          else:
                              # Main has stable release
                              entry_clean['name'] = "RasQberry Two (64-bit)"
                              entry_clean['description'] = "Stable release for Raspberry Pi 4/5 (Recommended)"
                              main_std.append((published, branch_name, entry_clean))
                              print(f"  → Top-level Main: {entry_clean['name']}")
                      else:
                          # Unknown branch pattern - treat as dev
                          entry_clean['name'] = f"RasQberry Two ({branch_name})"
                          dev_std.append((published, branch_name, entry_clean))
                          print(f"  → Dev folder (unknown): {entry_clean['name']}")

              except Exception as e:
                  print(f"  Error loading {json_file}: {e}")

          # Sort each category by release_date (newest first)
          main_std.sort(key=lambda x: x[0], reverse=True)
          beta_std.sort(key=lambda x: x[0], reverse=True)
          dev_std.sort(key=lambda x: x[0], reverse=True)
          dev_all.sort(key=lambda x: x[0], reverse=True)
          ab_all.sort(key=lambda x: x[0], reverse=True)

          # Build hierarchical os_list
          os_list = []

          # 1. Add main stable images (top-level) - only latest
          if main_std:
              os_list.append(main_std[0][2])
              print(f"\n✓ Added main stable: {main_std[0][2].get('name')}")

          # 2. Add beta images (top-level) - only latest
          if beta_std:
              os_list.append(beta_std[0][2])
              print(f"✓ Added beta: {beta_std[0][2].get('name')}")

          # 3. Add development images (top-level) - only latest
          if dev_std:
              os_list.append(dev_std[0][2])
              print(f"✓ Added development: {dev_std[0][2].get('name')}")

          # 5. Add Development Images folder (flat list of all dev-* branches)
          if dev_all:
              dev_folder = {
                  "name": "RasQberry Development Images",
                  "description": "Development builds with cutting-edge features (unstable)",
                  "icon": "https://rasqberry.org/Artwork/RasQberry 2 Logo Cube 64x64.png",
                  "subitems": [entry for _, _, entry in dev_all]
              }
              os_list.append(dev_folder)
              print(f"✓ Added Development folder with {len(dev_all)} images")

          # 6. Add A/B Test Images folder (flat list of all A/B images)
          if ab_all:
              ab_folder = {
                  "name": "RasQberry A/B Boot Images",
                  "description": "Images with A/B partition support for safer updates (experimental)",
                  "icon": "https://rasqberry.org/Artwork/RasQberry 2 Logo Cube 64x64.png",
                  "subitems": [entry for _, _, entry in ab_all]
              }
              os_list.append(ab_folder)
              print(f"✓ Added A/B folder with {len(ab_all)} images")

          # Build final consolidated structure
          consolidated = {
              "imager": {
                  "latest_version": "1.8.5",
                  "url": "https://www.raspberrypi.com/software/"
              },
              "os_list": os_list
          }

          print(f"\n=== Built hierarchical structure with {len(os_list)} top-level entries ===")

          # Fetch official Raspberry Pi OS entry from their JSON
          try:
              with open('/tmp/rpi-official.json', 'r') as f:
                  rpi_data = json.load(f)

              # Navigate the structure to find Raspberry Pi OS (64-bit)
              # The official JSON has nested structure with os_list containing subitems
              def find_raspios_64bit(items):
                  for item in items:
                      name = item.get('name', '')
                      # Look for the recommended 64-bit desktop version
                      if 'Raspberry Pi OS' in name and '64-bit' in name and 'Lite' not in name and 'Full' not in name:
                          # Check if it has direct download info or subitems
                          if 'url' in item:
                              return item
                          if 'subitems' in item:
                              # Look in subitems for the main desktop version
                              for sub in item['subitems']:
                                  sub_name = sub.get('name', '')
                                  if 'Desktop' in sub_name or ('64-bit' in sub_name and 'Lite' not in sub_name):
                                      if 'url' in sub:
                                          return sub
                      # Recurse into subitems
                      if 'subitems' in item:
                          result = find_raspios_64bit(item['subitems'])
                          if result:
                              return result
                  return None

              raspios_entry = find_raspios_64bit(rpi_data.get('os_list', []))

              if raspios_entry:
                  # Clean up the entry to match our schema
                  clean_entry = {
                      "name": raspios_entry.get('name', 'Raspberry Pi OS (64-bit)'),
                      "description": raspios_entry.get('description', 'Official Raspberry Pi OS'),
                      "icon": raspios_entry.get('icon', 'https://downloads.raspberrypi.com/raspios_armhf/Raspberry_Pi_OS_(32-bit).png'),
                      "url": raspios_entry.get('url'),
                      "extract_size": raspios_entry.get('extract_size'),
                      "extract_sha256": raspios_entry.get('extract_sha256'),
                      "image_download_size": raspios_entry.get('image_download_size'),
                      "release_date": raspios_entry.get('release_date'),
                      "init_format": raspios_entry.get('init_format', 'systemd'),
                      "devices": raspios_entry.get('devices', ['pi5-64bit', 'pi4-64bit'])
                  }
                  # Remove None values
                  clean_entry = {k: v for k, v in clean_entry.items() if v is not None}
                  consolidated['os_list'].append(clean_entry)
                  print(f"\n✓ Added official Raspberry Pi OS entry: {clean_entry.get('name')}")
                  print(f"  Release date: {clean_entry.get('release_date')}")
              else:
                  print("\n⚠ Could not find Raspberry Pi OS (64-bit) in official JSON")
                  raise Exception("Fallback needed")

          except Exception as e:
              print(f"\n⚠ Error fetching official Raspberry Pi OS: {e}")
              print("  Using fallback entry (may be outdated)")
              # Fallback to a known working entry
              consolidated['os_list'].append({
                  "name": "Raspberry Pi OS (64-bit)",
                  "description": "A port of Debian Bookworm with the Raspberry Pi Desktop (Recommended)",
                  "icon": "https://downloads.raspberrypi.com/raspios_armhf/Raspberry_Pi_OS_(32-bit).png",
                  "url": "https://downloads.raspberrypi.com/raspios_arm64/images/raspios_arm64-2024-10-28/2024-10-22-raspios-bookworm-arm64.img.xz",
                  "extract_size": 6102712320,
                  "extract_sha256": "88093218a66cf20e8669963902a949c4c23b73309c2fc3331d09fa6ee2134417",
                  "image_download_size": 1238664180,
                  "release_date": "2024-10-22",
                  "init_format": "systemd",
                  "devices": ["pi5-64bit", "pi4-64bit"]
              })

          # Note: Pi Imager has built-in "Use custom" option, no need to add our own

          # Write consolidated JSON to public folder (where website serves from)
          with open('public/RQB-images.json', 'w') as f:
              json.dump(consolidated, f, indent=2)

          print("\n=== Final RQB-images.json ===")
          print(json.dumps(consolidated, indent=2))

          # ================================================================
          # Generate RQB-releases.json for website /latest/ redirects
          # ================================================================
          from datetime import datetime, timezone

          def build_stream_entry(entries, stream_type):
              """Build a stream entry from the first (newest) entry in the list."""
              if not entries:
                  # No release available - return placeholder
                  messages = {
                      'stable': 'No stable release yet. Please use beta or dev.',
                      'beta': 'No beta release yet. Please use dev.',
                      'dev': 'No development release available.'
                  }
                  return {
                      'tag': None,
                      'name': None,
                      'message': messages.get(stream_type, 'No release available.'),
                      'release_url': 'https://github.com/${{ github.repository }}/releases'
                  }

              # Get the newest entry (already sorted by date)
              _, branch_name, entry = entries[0]

              # Extract tag from release_url or url
              tag = None
              release_url = entry.get('release_url', '')
              if '/releases/tag/' in release_url:
                  tag = release_url.split('/releases/tag/')[-1]
              elif '/releases/download/' in entry.get('url', ''):
                  # Extract from download URL: .../releases/download/TAG/filename
                  parts = entry.get('url', '').split('/releases/download/')
                  if len(parts) > 1:
                      tag = parts[1].split('/')[0]

              # Build the stream entry
              stream_entry = {
                  'tag': tag,
                  'name': entry.get('url', '').split('/')[-1].replace('.img.xz', '') if entry.get('url') else None,
                  'image_url': entry.get('url'),
                  'release_url': release_url or f"https://github.com/${{ github.repository }}/releases/tag/{tag}" if tag else f"https://github.com/${{ github.repository }}/releases",
                  'release_date': entry.get('release_date'),
                  'image_download_size': entry.get('image_download_size'),
              }

              # Add optional fields if present
              if entry.get('extract_size'):
                  stream_entry['extract_size'] = entry.get('extract_size')
              if entry.get('extract_sha256'):
                  stream_entry['extract_sha256'] = entry.get('extract_sha256')

              # Add highlights placeholder (can be enhanced later)
              stream_entry['highlights'] = ['extract highlights from GitHub release body']

              return stream_entry

          # Build RQB-releases.json
          # Use development branch for dev stream if available, otherwise fallback to dev-featuresXX
          if dev_std:
              all_dev = dev_std  # Use the permanent development integration branch
          else:
              # Fallback: use dev_all for the dev stream (newest overall)
              all_dev = dev_all
          releases_json = {
              'generated': datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ'),
              'streams': {
                  'stable': build_stream_entry(main_std, 'stable'),
                  'beta': build_stream_entry(beta_std, 'beta'),
                  'dev': build_stream_entry(all_dev, 'dev'),
              }
          }

          # Write RQB-releases.json
          with open('public/RQB-releases.json', 'w') as f:
              json.dump(releases_json, f, indent=2)

          print("\n=== Final RQB-releases.json ===")
          print(json.dumps(releases_json, indent=2))

          # ================================================================
          # Generate RQB-images-all.json with ALL releases
          # ================================================================
          # Sort all_releases by published date (newest first)
          all_releases.sort(key=lambda x: x.get('_published', ''), reverse=True)

          all_images_json = {
              "generated": datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ'),
              "description": "All RasQberry image versions for development and testing",
              "count": len(all_releases),
              "releases": all_releases
          }

          with open('public/RQB-images-all.json', 'w') as f:
              json.dump(all_images_json, f, indent=2)

          print(f"\n=== RQB-images-all.json: {len(all_releases)} entries ===")
          PYTHON_SCRIPT

      - name: Commit consolidated JSON files to gh-pages
        id: commit
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          git add public/RQB-images.json public/RQB-releases.json public/RQB-images-all.json

          # Check if there are changes
          if git diff --staged --quiet; then
            echo "No changes to JSON files"
            echo "changes=false" >> $GITHUB_OUTPUT
          else
            git commit -m "Consolidate RQB JSON files from release assets (triggered by ${{ github.event.inputs.trigger_source || github.event_name }})"

            # Retry push with pull --rebase to handle race conditions
            # (multiple workflows triggered by concurrent releases)
            for i in 1 2 3; do
              if git push origin gh-pages; then
                echo "✓ RQB-images.json and RQB-releases.json committed to gh-pages"
                echo "changes=true" >> $GITHUB_OUTPUT
                exit 0
              else
                echo "Push failed (attempt $i), pulling and retrying..."
                git pull --rebase origin gh-pages
              fi
            done
            echo "Failed to push after 3 attempts"
            exit 1
          fi

      - name: Trigger Next.js deployment
        if: steps.commit.outputs.changes == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Triggering Next.js deployment to update website..."
          gh workflow run "Deploy Next.js site to Pages" --ref gh-pages
          echo "✓ Next.js deployment triggered"

      - name: Summary
        run: |
          echo "=== Consolidation Complete ==="
          echo ""
          echo "Trigger: ${{ github.event_name }}"
          if [ "${{ github.event_name }}" = "schedule" ]; then
            echo "  (Scheduled 8-hour run to detect new/deleted releases)"
          elif [ "${{ github.event_name }}" = "release" ]; then
            echo "  (Release event detected)"
          fi
          echo ""
          echo "Source: GitHub Release Assets (RQB-images.json)"
          echo ""
          echo "Generated files on gh-pages:"
          echo ""
          echo "1. RQB-images.json (Pi Imager - hierarchical structure):"
          echo "   ├── RasQberry Two (64-bit)         - Main stable"
          echo "   ├── RasQberry Two Beta (64-bit)    - Beta release"
          echo "   ├── RasQberry Two Dev (64-bit)     - Development integration"
          echo "   ├── RasQberry Development Images   - dev-featuresXX builds"
          echo "   ├── RasQberry A/B Boot Images      - A/B images folder"
          echo "   └── Raspberry Pi OS (64-bit)       - Official Pi OS"
          echo ""
          echo "2. RQB-releases.json (Website /latest/ - stream structure):"
          echo "   ├── streams.stable  - Latest main branch release"
          echo "   ├── streams.beta    - Latest beta branch release"
          echo "   └── streams.dev     - Latest development branch release"
          echo ""
          echo "3. RQB-images-all.json (All versions for development/testing):"
          echo "   └── All historical releases from all branches"
          echo ""
          echo "Access URLs:"
          echo "  Pi Imager:   https://rasqberry.org/RQB-images.json"
          echo "  Website:     https://rasqberry.org/RQB-releases.json"
          echo "  All Images:  https://rasqberry.org/RQB-images-all.json"
          echo "  Downloads:   https://rasqberry.org/latest/"
