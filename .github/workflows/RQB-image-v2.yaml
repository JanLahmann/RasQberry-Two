# ============================================================================
# RasQberry Pi Image Build Workflow
# ============================================================================
# Purpose: Automates the building of custom Raspberry Pi OS images for the 
#          RasQberry quantum computing education platform.
#
# Key Features:
# - Automated versioning with semantic versioning support
# - Intelligent caching system for faster development builds
# - Automatic GitHub releases with built images
# - Memory and disk optimization for GitHub Actions runners
# - Support for both development and production builds
#
# Trigger Conditions:
# - Manual workflow dispatch (with optional version override)
# - Automatic on push to dev* branches
# ============================================================================

# ============================================================================
# BUILD ARCHITECTURE OVERVIEW
# ============================================================================
# 
# ┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
# │ Version Manager │────▶│ Release Creator │────▶│  Image Builder  │
# └─────────────────┘     └─────────────────┘     └─────────────────┘
#         │                        │                        │
#         ▼                        ▼                        ▼
#   Update VERSION          Create GitHub          Build Pi Image
#   Create Git Tag          Release with           - Use cache (dev)
#   Push Changes            Changelog              - Fresh (main)
#                                                   - Upload Asset
#
# CACHING STRATEGY (Dev Builds Only):
# 
# First Build:          Subsequent Builds:       Monthly/Forced:
# ┌──────────┐         ┌──────────┐            ┌──────────┐
# │ Stage 0  │         │ Stage 0  │            │ Stage 0  │
# │ Stage 1  │ Build   │ Stage 1  │ From       │ Stage 1  │ Rebuild
# │ Stage 2  │ All     │ Stage 2  │ Cache      │ Stage 2  │ All
# │ Stage 3  │   ↓     │ Stage 3  │  (Skip)    │ Stage 3  │   ↓
# │ Stage 4  │ Save    │ Stage 4  │   │        │ Stage 4  │ Save
# ├──────────┤ Cache   ├──────────┤   ▼        ├──────────┤ Cache
# │ RasQberry│   ↓     │ RasQberry│ Build      │ RasQberry│   ↓
# └──────────┘         └──────────┘ Only       └──────────┘
# ============================================================================


# ============================================================================
# ENVIRONMENT VARIABLES REFERENCE
# ============================================================================
#
# Custom Variables (from pi-gen-config):
#   - CACHE_VERSION: Increment to invalidate all caches
#   - RQB_*: RasQberry-specific build configuration
#     - RQB_REPO: Repository name (set dynamically)
#     - RQB_GIT_USER: GitHub username (set dynamically)
#     - RQB_GIT_BRANCH: Branch to build from (set dynamically)
#     - RQB_STD_VENV: Standard virtual environment name
#     - RQB_CONFDIR: Configuration directory path
#
# Pi-gen Variables (from pi-gen-config):
#   - FIRST_USER_NAME: Default user (rasqberry)
#   - IMG_NAME: Output image name prefix
#   - SKIP_INITRAMFS: Speed optimization flag
# ============================================================================

name: Rasqberry Pi Image Release v2

# Concurrency control: Only one workflow per branch, cancel previous runs
concurrency:
  group: rasqberry-build-${{ github.ref }}
  cancel-in-progress: true

# GitHub permissions required for this workflow
permissions:
  contents: write      # Create releases and push tags
  checks: write        # Update check status
  id-token: write      # Sign artifacts with cosign
  packages: write      # Push to GitHub container registry

# ============================================================================
# WORKFLOW TRIGGERS
# ============================================================================
on:
  # Manual trigger with input parameters
  workflow_dispatch:
    inputs:
      version:
        description: 'Version number (required for main branch)'
        required: false
        type: string
      refresh_cache:
        description: 'Force cache refresh (dev branches only)'
        required: false
        type: boolean
        default: false
      build_cache:
        description: 'Enable caching for main branch (to seed cross-branch cache)'
        required: false
        type: boolean
        default: false
      publish_json:
        description: 'Publish generated JSON to gh-pages (JSON always created locally)'
        required: false
        type: boolean
        default: false
  
  # Automatic trigger for development branches
  #push:
  #  branches:
  #    - dev*    # Matches: dev, dev-feature, development, etc.

# ============================================================================
# GLOBAL ENVIRONMENT VARIABLES
# ============================================================================
env:
  # Cache versioning - increment this to invalidate all caches
  CACHE_VERSION: v1

# ============================================================================
# JOB 1: Version Management
# ============================================================================
# This job handles semantic versioning and creates git tags
# For main branch: Requires semantic version (e.g., 1.2.3)
# For dev branches: Auto-generates version with timestamp
jobs:
  rasqberry-push-version-number:
    name: "Rasqberry: Push version number"
    runs-on: ubuntu-latest
    outputs:
      # Version outputs for use in subsequent jobs
      version: ${{ steps.current-version.outputs.version }}
      version_num: ${{ steps.update-version.outputs.version_num }}
    
    steps:
      # Clone the repository with push permissions
      - name: "Rasqberry: Clone Repository"
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository }}
          token: ${{ secrets.GITHUB_TOKEN }}
          persist-credentials: true  # Needed for pushing tags

      # Generate timestamp for dev branch versions
      - name: Create Date
        id: create-date
        shell: bash
        run: |
          NOW="$(date +"%Y-%m-%d-%H%M%S")"
          echo "date=${NOW}" >> $GITHUB_OUTPUT

      # Read the current version from VERSION file
      - name: "Rasqberry: Get current version"
        id: current-version
        shell: bash
        run: |
          version=$(cat ./VERSION)
          echo "version=${version}" >> $GITHUB_OUTPUT

      # Update version file with new version number
      # Logic:
      # - Main branch: Must provide semantic version via input
      # - Dev branches: Use input if provided, else branch-timestamp
      - name: "Rasqberry: Add version file"
        id: update-version
        if: ${{ steps.current-version.outputs.version != github.event.inputs.version }}
        shell: bash
        env:
          VERSION_INPUT: ${{ github.event.inputs.version }}
          CREATE_DATE: ${{ steps.create-date.outputs.date }}
        run: |
          BRANCH_NAME=${GITHUB_REF#refs/heads/}
          
          # Main branch requires explicit semantic version
          if [ "$BRANCH_NAME" = "main" ]; then
            if [ -z "$VERSION_INPUT" ]; then
              echo "Error: On 'main' branch you must supply a semantic version via workflow inputs." >&2
              exit 1
            fi
            VERSION_NUMBER="$VERSION_INPUT"
          else
            # Dev branches: Use input or generate from branch name + timestamp
            if [ -n "$VERSION_INPUT" ]; then
              VERSION_NUMBER="$VERSION_INPUT"
            else
              VERSION_NUMBER="${BRANCH_NAME}-${CREATE_DATE}"
            fi
          fi
          
          echo "version_num=$VERSION_NUMBER" >> $GITHUB_OUTPUT
          echo "$VERSION_NUMBER" > ./VERSION

      # Validate semantic version format for main branch releases
      - name: "Validate semantic version"
        if: github.ref == 'refs/heads/main'
        shell: bash
        run: |
          echo "$VERSION_INPUT" | grep -Eq '^[0-9]+\.[0-9]+\.[0-9]+$' \
            || { echo "⛔ Invalid semantic version: $VERSION_INPUT" >&2; exit 1; }
        
      # Commit version change and create/update git tag
      # Tags: v1.2.3 for main, branch-timestamp for dev
      - name: "Rasqberry: git add & commit & push"
        uses: EndBug/add-and-commit@v9
        with:
          add: "./VERSION"
          default_author: github_actions
          message: "Bump version to ${{ steps.update-version.outputs.version_num }}"
          github_token: ${{ secrets.GITHUB_TOKEN }}
          # Force push tags to allow re-running builds with same version
          tag: ${{ github.ref == 'refs/heads/main' && format('v{0} --force', steps.update-version.outputs.version_num) || format('{0} --force', steps.update-version.outputs.version_num) }}
          push: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # Install cosign for artifact signing (future enhancement)
      - name: Install cosign
        uses: sigstore/cosign-installer@v3.5.0
        with:
          cosign-release: 'v2.2.4'

  # ============================================================================
  # JOB 2: Create GitHub Release
  # ============================================================================
  # Creates a GitHub release with changelog for the new version
  release:
    name: Create Release
    needs: rasqberry-push-version-number
    runs-on: ubuntu-latest
    outputs:
      # Release outputs for asset upload
      id: ${{ steps.create-release.outputs.id }}
      upload_url: ${{ steps.create-release.outputs.upload_url }}
    
    steps:
      # Checkout with full history for changelog generation
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history needed for git-cliff

      # Get the most recent tag for changelog generation
      - name: Get latest tag
        id: latest_tag
        shell: bash
        run: |
          echo "TAG_NAME=$(git describe --tags $(git rev-list --tags --max-count=1))" >> $GITHUB_OUTPUT

      # Generate changelog from commits since last tag
      - name: Generate a changelog
        uses: orhun/git-cliff-action@v1
        id: changelog
        with:
          config: ./cliff-release.toml  # Changelog format configuration
          args: ${{ steps.latest_tag.outputs.TAG_NAME }}..HEAD

      # Create GitHub release with generated changelog
      # Release naming:
      # - Main: "rasqberry-v1.2.3"
      # - Dev: "rasqberry-dev-2024-01-01-123456"
      - name: Create Release
        id: create-release
        uses: softprops/action-gh-release@v2.2.1
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          name: ${{ github.ref == 'refs/heads/main' && format('rasqberry-v{0}', needs.rasqberry-push-version-number.outputs.version_num) || format('rasqberry-{0}', needs.rasqberry-push-version-number.outputs.version_num) }}
          tag_name: ${{ github.ref == 'refs/heads/main' && format('v{0}', needs.rasqberry-push-version-number.outputs.version_num) || needs.rasqberry-push-version-number.outputs.version_num }}
          body: ${{ steps.changelog.outputs.content }}
          make_latest: true  # Mark as latest release

  # ============================================================================
  # JOB 3: Build Raspberry Pi Image
  # ============================================================================
  # This job builds the actual Raspberry Pi OS image using pi-gen
  # Includes sophisticated caching for development builds
  build:
    name: Build Image
    needs: [release]
    runs-on: ubuntu-latest
    outputs:
      # Output paths for the built image
      asset_path: ${{ steps.set-asset.outputs.asset_path }}
      asset_name: ${{ steps.set-asset.outputs.asset_name }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # ========================================================================
      # DISK SPACE OPTIMIZATION
      # ========================================================================
      # GitHub Actions runners have limited disk space (~14GB free)
      # Pi-gen needs significant space for building images
      - name: Free up disk space
        run: |
          echo "=== Before cleanup ==="
          df -h
          
          # Remove large pre-installed tools we don't need
          # Each line frees several GB of space
          sudo rm -rf /usr/share/dotnet          # .NET SDK
          sudo rm -rf /opt/ghc                   # Haskell compiler
          sudo rm -rf /usr/local/share/boost     # Boost C++ libraries
          sudo rm -rf /usr/local/lib/android     # Android SDK
          sudo rm -rf /opt/hostedtoolcache       # Various cached tools
          sudo rm -rf /usr/local/graalvm         # GraalVM JDK
          sudo rm -rf /usr/local/.ghcup          # Haskell toolchain
          sudo rm -rf /usr/local/share/powershell # PowerShell
          sudo rm -rf /usr/local/lib/node_modules # Node.js global modules
          
          echo "=== After cleanup ==="
          df -h

      # ========================================================================
      # MEMORY OPTIMIZATION
      # ========================================================================
      # Pi-gen is memory intensive, especially during compression
      # Create large swap file to prevent OOM errors
      - name: Maximize available memory
        run: |
          echo "=== Initial memory status ==="
          free -h
          
          # Stop unnecessary services to free RAM
          echo "Stopping unnecessary services..."
          sudo systemctl stop mysql || true
          sudo systemctl stop postgresql || true
          sudo systemctl stop apache2 || true
          sudo systemctl stop snapd || true
          sudo systemctl stop google-chrome || true
          sudo systemctl stop firefox || true
          sudo systemctl stop dotnet || true
          
          # Remove existing swap
          sudo swapoff -a || true
          sudo rm -f /swapfile || true
          
          # Create larger swap file (10GB)
          echo "Creating 10GB swap file..."
          sudo fallocate -l 10G /swapfile
          sudo chmod 600 /swapfile
          sudo mkswap /swapfile
          sudo swapon /swapfile
          
          echo "=== Final memory status ==="
          free -h
          echo "=== Swap status ==="
          sudo swapon --show

      # ========================================================================
      # CACHE CONFIGURATION
      # ========================================================================
      # Display what cache key we're looking for (debugging aid)
      - name: List available caches
        run: |
          echo "Current branch: ${GITHUB_REF#refs/heads/}"
          echo "Cache key pattern: stage4-${{ env.CACHE_VERSION }}-$(date +"%Y-%m")-bookworm-arm64"
          # Note: Can't actually list caches, but shows the key format

      # Determine if this build should use caching
      # Rules:
      # - Main branch: Cache disabled by default, enabled with build_cache input
      # - Beta branch: Cache always disabled (production builds always fresh)
      # - Dev branches: Cache enabled for faster development
      # - Manual refresh_cache input forces fresh build
      - name: Determine if caching should be used
        id: cache-decision
        run: |
          BRANCH_NAME=${GITHUB_REF#refs/heads/}
          FORCE_REFRESH="${{ github.event.inputs.refresh_cache }}"
          BUILD_CACHE="${{ github.event.inputs.build_cache }}"
          
          if [[ "$BRANCH_NAME" == "main" ]]; then
            if [ "$BUILD_CACHE" == "true" ]; then
              echo "use_cache=true" >> $GITHUB_OUTPUT
              echo "Cache enabled for main branch (manual override - will seed cross-branch cache)"
            else
              echo "use_cache=false" >> $GITHUB_OUTPUT
              echo "Cache disabled for main branch (production build - use build_cache input to enable)"
            fi
          elif [[ "$BRANCH_NAME" == "beta" ]]; then
            echo "use_cache=false" >> $GITHUB_OUTPUT
            echo "Cache disabled for production branch: $BRANCH_NAME"
          else
            if [ "$FORCE_REFRESH" == "true" ]; then
              echo "use_cache=false" >> $GITHUB_OUTPUT
              echo "Cache refresh forced by workflow input"
            else
              echo "use_cache=true" >> $GITHUB_OUTPUT
              echo "Cache enabled for development branch: $BRANCH_NAME"
            fi
          fi

      # Generate cache key with monthly rotation
      # This ensures caches are refreshed monthly for security updates
      - name: Generate cache date
        id: cache-date
        if: steps.cache-decision.outputs.use_cache == 'true'
        run: |
          # Use year-month for cache key to refresh monthly
          CACHE_DATE=$(date +"%Y-%m")
          echo "cache_date=${CACHE_DATE}" >> $GITHUB_OUTPUT

      # ========================================================================
      # CACHE RESTORATION - Base Stages Only
      # ========================================================================
      # Cache only the base stages (0-4) which are shared across all dev branches
      # Custom stage-RQB2 always builds fresh to ensure branch-specific changes
      - name: Restore Base Stages Cache (0-4)
        id: cache-base-stages
        if: steps.cache-decision.outputs.use_cache == 'true'
        uses: actions/cache/restore@v4
        with:
          path: base-stages-cache.tar.gz
          key: base-stages-${{ env.CACHE_VERSION }}
          restore-keys: |
            base-stages-${{ env.CACHE_VERSION }}-

      # Cache frequently downloaded apt packages
      - name: Cache apt packages
        id: cache-apt
        uses: actions/cache@v3
        with:
          path: ~/apt-cache
          key: apt-packages-${{ runner.os }}-pigen-deps-v1
          restore-keys: |
            apt-packages-${{ runner.os }}-pigen-deps-
          
      # ========================================================================
      # PI-GEN DEPENDENCIES
      # ========================================================================
      # Install required packages for running pi-gen
      # Uses apt package caching to speed up repeated builds
      - name: Install pi-gen dependencies
        run: |
          # Create cache directory for apt packages
          mkdir -p ~/apt-cache
          
          # Configure apt to keep downloaded packages
          echo 'Binary::apt::APT::Keep-Downloaded-Packages "true";' | sudo tee /etc/apt/apt.conf.d/01cache
          
          # Restore cached packages if available
          if [ "${{ steps.cache-apt.outputs.cache-hit }}" == "true" ] && [ -n "$(ls -A ~/apt-cache/*.deb 2>/dev/null)" ]; then
            echo "Restoring apt packages from cache..."
            echo "Found $(ls ~/apt-cache/*.deb | wc -l) packages in cache"
            sudo cp -n ~/apt-cache/*.deb /var/cache/apt/archives/ 2>/dev/null || true
          else
            echo "No cache found or cache is empty"
          fi
          
          # Update package lists
          sudo apt-get update
          
          # Install pi-gen dependencies
          # These are required for cross-compilation and image building
          sudo apt-get install -y \
            coreutils \
            quilt \
            parted \
            qemu-user-static \
            debootstrap \
            zerofree \
            zip \
            dosfstools \
            libarchive-tools \
            libcap2-bin \
            grep \
            rsync \
            xz-utils \
            file \
            git \
            curl \
            bc \
            gpg \
            pigz \
            lz4 \
            arch-test
          
          # Save downloaded packages to cache
          echo "Copying packages to cache directory..."
          cp -v /var/cache/apt/archives/*.deb ~/apt-cache/ 2>/dev/null || true
          echo "Cache now contains $(ls ~/apt-cache/*.deb 2>/dev/null | wc -l) packages"
          echo "Cache size: $(du -sh ~/apt-cache | cut -f1)"

      # ========================================================================
      # DEBIAN KEYRING FIX
      # ========================================================================
      # Update Debian archive keyring on the runner to prevent GPG verification errors
      # This ensures the latest Debian signing keys are available for debootstrap
      - name: Update Debian archive keyring
        run: |
          echo "Updating Debian archive keyring on GitHub Actions runner..."

          # Update package lists
          sudo apt-get update

          # Install/update the debian-archive-keyring package
          sudo apt-get install -y --reinstall debian-archive-keyring

          # Import missing Debian Bookworm signing keys as fallback
          # Using gpg instead of deprecated apt-key
          for key in 6ED0E7B82643E131 78DBA3BC47EF2265 F8D2585B8783D481 54404762BBB6E853 BDE6D2B9216EC7A8; do
            echo "Importing key: $key"
            sudo gpg --keyserver keyserver.ubuntu.com --recv-keys "$key" || true
            sudo gpg --export "$key" | sudo tee /etc/apt/trusted.gpg.d/debian-${key}.gpg > /dev/null || true
          done

          echo "Debian keyring update completed"

      # Clone official Raspberry Pi image generator
      - name: Clone pi-gen
        run: |
          git clone --depth 1 --branch arm64 https://github.com/RPi-Distro/pi-gen
          cd pi-gen

      # Add Debian archive keyring to pi-gen files
      - name: Add Debian keyring to pi-gen stage0 files
        run: |
          echo "Copying Debian archive keyring to pi-gen/stage0/00-configure-apt/files/"

          # Copy the debian-archive-keyring.gpg to pi-gen files directory
          # This will be installed alongside raspberrypi-archive-keyring.gpg
          if [ -f "/usr/share/keyrings/debian-archive-keyring.gpg" ]; then
            cp /usr/share/keyrings/debian-archive-keyring.gpg \
               pi-gen/stage0/00-configure-apt/files/
            echo "✓ Copied debian-archive-keyring.gpg"
          else
            echo "⚠ Warning: debian-archive-keyring.gpg not found, checking alternatives..."
            # Try to find and copy any Debian keyring files
            find /usr/share/keyrings/ -name "debian-*" -exec cp {} pi-gen/stage0/00-configure-apt/files/ \;
          fi

          # Verify the file was copied
          if [ -f "pi-gen/stage0/00-configure-apt/files/debian-archive-keyring.gpg" ]; then
            echo "✓ Debian keyring ready for installation"
            ls -lh pi-gen/stage0/00-configure-apt/files/debian-archive-keyring.gpg
          else
            echo "❌ Failed to copy Debian keyring"
            exit 1
          fi

      # Modify stage0 apt config to install Debian keyring
      - name: Patch stage0 to install Debian keyring
        run: |
          cat > /tmp/patch.txt << 'PATCH'
          --- a/stage0/00-configure-apt/00-run.sh
          +++ b/stage0/00-configure-apt/00-run.sh
          @@ -18,6 +18,7 @@
           fi

           install -m 644 files/raspberrypi-archive-keyring.pgp "${ROOTFS_DIR}/usr/share/keyrings/"
          +install -m 644 files/debian-archive-keyring.gpg "${ROOTFS_DIR}/usr/share/keyrings/" || true
           on_chroot <<- \EOF
           	ARCH="$(dpkg --print-architecture)"
           	if [ "$ARCH" = "armhf" ]; then
          PATCH

          # Apply the modification directly
          cd pi-gen/stage0/00-configure-apt
          sed -i '/install -m 644 files\/raspberrypi-archive-keyring.pgp/a install -m 644 files/debian-archive-keyring.gpg "${ROOTFS_DIR}/usr/share/keyrings/" || echo "Warning: Could not install debian-archive-keyring.gpg"' 00-run.sh

          echo "✓ Patched stage0/00-configure-apt/00-run.sh to install Debian keyring"
          echo "Modified script:"
          cat 00-run.sh

      # Extract cached base stages if cache was hit (after pi-gen exists)
      - name: Extract cached base stages
        if: steps.cache-decision.outputs.use_cache == 'true' && steps.cache-base-stages.outputs.cache-hit == 'true'
        run: |
          echo "Extracting cached base stages..."
          if [ -f "base-stages-cache.tar.gz" ]; then
            cd pi-gen
            sudo tar -xzf ../base-stages-cache.tar.gz
            echo "Cache extracted successfully"
            
            # Verify extraction
            if [ -d "work" ]; then
              echo "✓ Work directory restored from cache"
              ls -la work/
            else
              echo "❌ Work directory not found after extraction!"
              echo "Available directories:"
              ls -la
              exit 1
            fi
            
            # Clean up cache file to save space
            rm -f ../base-stages-cache.tar.gz
          else
            echo "❌ Cache file not found!"
            exit 1
          fi

      # ========================================================================
      # DYNAMIC CONFIGURATION
      # ========================================================================
      # Update build configuration with branch-specific settings and Git context
      # This ensures the image builds with correct quality and repository settings
      - name: Update pi-gen-config with branch-specific settings
        run: |
          BRANCH_NAME="${GITHUB_REF_NAME}"
          
          # Branch-specific quality settings override using config file values
          if [[ "$BRANCH_NAME" == "main" || "$BRANCH_NAME" == "beta" ]]; then
            echo "Applying production build settings for: $BRANCH_NAME"
            
            # Read production values from config file
            SKIP_INITRAMFS_PROD=$(grep "^SKIP_INITRAMFS_PROD=" pi-gen-config | cut -d'=' -f2)
            COMPRESSION_LEVEL_PROD=$(grep "^COMPRESSION_LEVEL_PROD=" pi-gen-config | cut -d'=' -f2)
            
            # Apply production values
            sed -i "s/^SKIP_INITRAMFS=.*/SKIP_INITRAMFS=${SKIP_INITRAMFS_PROD}/" pi-gen-config
            sed -i "s/^COMPRESSION_LEVEL=.*/COMPRESSION_LEVEL=${COMPRESSION_LEVEL_PROD}/" pi-gen-config
          else
            echo "Using development build settings for: $BRANCH_NAME"
            # Keep existing dev values from config file
          fi
          
          # Conditional Git variable update (only if placeholder present)
          if grep -q "will-be-set-in-gh-workflow" pi-gen-config; then
            echo "Updating Git variables (placeholder values detected)"
            REPO_NAME="${GITHUB_REPOSITORY#*/}"
            REPO_OWNER="${GITHUB_REPOSITORY_OWNER}"
            
            sed -i "s|RQB_REPO=will-be-set-in-gh-workflow|RQB_REPO=${REPO_NAME}|" pi-gen-config
            sed -i "s|RQB_GIT_USER=will-be-set-in-gh-workflow|RQB_GIT_USER=${REPO_OWNER}|" pi-gen-config  
            sed -i "s|RQB_GIT_BRANCH=will-be-set-in-gh-workflow|RQB_GIT_BRANCH=${BRANCH_NAME}|" pi-gen-config
          else
            echo "Git variables manually set, preserving existing values"
          fi
          
          # Show final configuration for verification
          echo "=== Final pi-gen-config settings ==="
          echo "Build Quality:"
          grep -E "^(SKIP_INITRAMFS|COMPRESSION_LEVEL)=" pi-gen-config
          echo "Git Configuration:"
          grep -E "^RQB_(REPO|GIT_USER|GIT_BRANCH)=" pi-gen-config

      # Configure pi-gen with our custom settings
      - name: Configure build
        run: |
          cd pi-gen
          cp ../pi-gen-config config

      # ========================================================================
      # BASE STAGE BUILD (Conditional)
      # ========================================================================
      # Build stages 0-4 only if:
      # 1. Cache is disabled, OR
      # 2. Cache miss (no existing cache found)
      - name: Build base stages (if not cached or cache disabled)
        if: steps.cache-decision.outputs.use_cache == 'false' || steps.cache-base-stages.outputs.cache-hit != 'true'
        run: |
          cd pi-gen
          echo "Building base stages 0-4..."
          
          # Configure to build only base stages
          echo 'STAGE_LIST="stage0 stage1 stage2 stage3 stage4"' >> config
          
          # Skip image export for intermediate stages (saves time)
          touch ./stage0/SKIP_IMAGES ./stage1/SKIP_IMAGES ./stage2/SKIP_IMAGES
          touch ./stage3/SKIP_IMAGES ./stage4/SKIP_IMAGES
          
          # Skip stage5 (desktop software - not needed)
          touch ./stage5/SKIP
          
          # Run the build
          sudo ./build.sh
          
          # Clean up any custom stage remnants to prepare for fresh custom build
          sudo rm -rf work/*/stage-RQB2 || true
          
          echo "Base stages 0-4 build completed"

      # ========================================================================
      # IMMEDIATE CACHE SAVE - Base Stages
      # ========================================================================
      # Save the cache immediately after base stages complete to prevent loss
      # if custom stage fails. Only save if we built the base stages.
      - name: Save Base Stages Cache (Immediate)
        if: steps.cache-decision.outputs.use_cache == 'true' && (steps.cache-base-stages.outputs.cache-hit != 'true')
        run: |
          echo "Creating tarball of base stages work directory..."
          cd pi-gen
          
          # Create tarball with fast compression, excluding stage-RQB2 directories
          sudo tar -czf ../base-stages-cache.tar.gz \
            --exclude="work/*/stage-RQB2" \
            work/
          
          echo "Tarball created successfully"
          ls -lh ../base-stages-cache.tar.gz
          
      # Cache the tarball (separate step for cleaner error handling)
      - name: Cache Base Stages Tarball
        if: steps.cache-decision.outputs.use_cache == 'true' && (steps.cache-base-stages.outputs.cache-hit != 'true')
        uses: actions/cache/save@v4
        with:
          path: base-stages-cache.tar.gz
          key: base-stages-${{ env.CACHE_VERSION }}

      # Show system resources before main build
      - name: show swap and memory status before build
        run: |
          echo "=== Current memory status ==="
          free -h
          swapon --show

      # ========================================================================
      # CUSTOM STAGE BUILD
      # ========================================================================
      # Copy our custom RasQberry stage into pi-gen (after base stages are built)
      - name: Copy custom stage
        run: cp -r stage-RQB2 pi-gen/

      # Build the RasQberry-specific stage on top of base image
      - name: Build custom stage
        run: |
          cd pi-gen
          
          # Check if we have cached base stages
          if [ "${{ steps.cache-decision.outputs.use_cache }}" == "true" ] && [ "${{ steps.cache-base-stages.outputs.cache-hit }}" == "true" ]; then
            echo "Using cached base stages..."
            
            # Find the cached work directory
            WORK_DIR=$(find work -maxdepth 1 -type d ! -name work | head -1)
            
            if [ -n "$WORK_DIR" ]; then
              echo "Found cached work directory: $WORK_DIR"
              
              # Verify stage4 rootfs exists in cache
              if [ ! -d "$WORK_DIR/stage4/rootfs" ]; then
                echo "ERROR: stage4/rootfs missing from cache!"
                echo "Cache appears incomplete. Use 'refresh_cache' option to rebuild."
                exit 1
              fi
              
              # Set up for continuation build
              WORK_NAME=$(basename "$WORK_DIR")
              WORK_DIR_ABS="$(pwd)/work/$WORK_NAME"
              
              # Configure for continuation build from cached base
              echo "CONTINUE=1" >> config
              echo "WORK_DIR=$WORK_DIR_ABS" >> config
              echo 'STAGE_LIST="./stage-RQB2"' >> config
              
              # Ensure stage4 is marked as complete for continuation
              sudo mkdir -p "$WORK_DIR_ABS/stage4"
              sudo touch "$WORK_DIR_ABS/stage4/.build_done"
              
              # Update package lists in cached rootfs (may be stale)
              echo "Refreshing package lists in cached rootfs..."
              sudo chroot "$WORK_DIR_ABS/stage4/rootfs" apt-get update || echo "Warning: Failed to update package lists"
              
            else
              echo "ERROR: No work directory found in cache!"
              exit 1
            fi
          else
            echo "Building custom stage on fresh base..."
            
            # For fresh builds or no cache, continue from base build
            echo "CONTINUE=1" >> config
            echo 'STAGE_LIST="./stage-RQB2"' >> config
          fi
          
          # Show final configuration for debugging
          echo "=== Final config file ==="
          cat config
          echo "========================"
          
          # Build the custom RasQberry stage
          sudo ./build.sh

      # ========================================================================
      # IMAGE FINALIZATION
      # ========================================================================
      # Find the built image and prepare it for upload
      - name: Set dynamic asset path and name
        id: set-asset
        run: |
          # Ensure we're in the right directory
          if [ ! -d "pi-gen" ]; then
            echo "Error: pi-gen directory not found in $(pwd)"
            echo "Directory contents:"
            ls -la
            exit 1
          fi
          cd pi-gen
          mkdir -p ../deploy
          
          # Find the compressed image file
          FINAL_IMAGE=$(find deploy -name "*.img.xz" -type f | head -n 1)
          
          if [ -z "$FINAL_IMAGE" ]; then
            echo "Error: No image found in deploy directory"
            exit 1
          fi
          
          # Copy to deploy folder at workspace root
          cp "$FINAL_IMAGE" ../deploy/
          
          # Set outputs for upload step
          FILE_NAME=$(basename "$FINAL_IMAGE")
          echo "asset_path=deploy/$FILE_NAME" >> $GITHUB_OUTPUT
          echo "asset_name=$FILE_NAME" >> $GITHUB_OUTPUT
          
          # Display build information
          echo "Built image: $FILE_NAME"
          echo "Size: $(du -h ../deploy/$FILE_NAME | cut -f1)"
          
          # Log cache usage summary
          if [ "${{ steps.cache-decision.outputs.use_cache }}" == "true" ]; then
            echo "Build completed with base stage caching enabled"
            if [ "${{ steps.cache-base-stages.outputs.cache-hit }}" == "true" ]; then
              echo "Base stages cache hit - only custom stage-RQB2 was rebuilt"
            else
              echo "Base stages cache miss - full build was performed"
            fi
          else
            echo "Build completed without caching (production build)"
          fi

      # ========================================================================
      # RELEASE ASSET UPLOAD
      # ========================================================================
      # Upload the built image to the GitHub release
      - name: Upload Release Asset
        uses: actions/upload-release-asset@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          upload_url: ${{ needs.release.outputs.upload_url }}
          asset_path: ${{ steps.set-asset.outputs.asset_path }}
          asset_name: ${{ steps.set-asset.outputs.asset_name }}
          asset_content_type: application/x-xz  # XZ compressed disk image

  # ============================================================================
  # JOB 4: Generate and Upload RQB-images.json
  # ============================================================================
  # Always generates the JSON file, optionally uploads to gh-pages
  update-json:
    name: Generate RQB-images.json
    needs: [rasqberry-push-version-number, release, build]
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Download and calculate image metadata
        id: metadata
        run: |
          # Get the asset details from the build job
          ASSET_NAME="${{ needs.build.outputs.asset_name }}"
          DOWNLOAD_URL="https://github.com/${{ github.repository }}/releases/download/${{ github.ref == 'refs/heads/main' && format('v{0}', needs.rasqberry-push-version-number.outputs.version_num) || needs.rasqberry-push-version-number.outputs.version_num }}/${ASSET_NAME}"
          
          echo "Downloading image to calculate metadata: $ASSET_NAME"
          
          # Download the compressed image from the release
          curl -L -o "$ASSET_NAME" "$DOWNLOAD_URL"
          
          if [ ! -f "$ASSET_NAME" ]; then
            echo "Error: Failed to download image file"
            exit 1
          fi
          
          echo "Calculating metadata using streaming decompression..."
          
          # Get uncompressed size from xz metadata (no extraction needed)
          EXTRACT_SIZE=$(xz --list --robot "$ASSET_NAME" | tail -n 1 | awk '{print $5}')
          
          # Calculate SHA256 using streaming decompression (no disk write)
          echo "Streaming decompression to calculate SHA256 (this may take a few minutes)..."
          EXTRACT_SHA256=$(xz -d -c "$ASSET_NAME" | sha256sum | cut -d' ' -f1)
          
          # Calculate compressed image size
          COMPRESSED_SIZE=$(stat -c%s "$ASSET_NAME")
          
          # Clean up downloaded file to save space
          rm -f "$ASSET_NAME"
          
          RELEASE_DATE=$(date +"%Y-%m-%d")
          
          # Output all metadata
          echo "download_url=${DOWNLOAD_URL}" >> $GITHUB_OUTPUT
          echo "compressed_size=${COMPRESSED_SIZE}" >> $GITHUB_OUTPUT
          echo "extract_size=${EXTRACT_SIZE}" >> $GITHUB_OUTPUT
          echo "extract_sha256=${EXTRACT_SHA256}" >> $GITHUB_OUTPUT
          echo "release_date=${RELEASE_DATE}" >> $GITHUB_OUTPUT
          echo "version_num=${{ needs.rasqberry-push-version-number.outputs.version_num }}" >> $GITHUB_OUTPUT
          
          # Display calculated values
          echo "Image metadata calculated:"
          echo "  Compressed size: $COMPRESSED_SIZE bytes ($(numfmt --to=iec-i --suffix=B $COMPRESSED_SIZE))"
          echo "  Uncompressed size: $EXTRACT_SIZE bytes ($(numfmt --to=iec-i --suffix=B $EXTRACT_SIZE))"
          echo "  Uncompressed SHA256: $EXTRACT_SHA256"
          
      - name: Determine version type
        id: version-type
        run: |
          BRANCH_NAME="${GITHUB_REF#refs/heads/}"
          VERSION_NUM="${{ steps.metadata.outputs.version_num }}"
          
          if [[ "$BRANCH_NAME" == "main" ]]; then
            echo "type=main" >> $GITHUB_OUTPUT
            echo "name=RasQberry Two (64-bit)" >> $GITHUB_OUTPUT
            echo "description=RasQberry stable release for exploring Quantum Computing and Qiskit" >> $GITHUB_OUTPUT
          elif [[ "$BRANCH_NAME" == "beta" ]]; then
            echo "type=beta" >> $GITHUB_OUTPUT
            echo "name=RasQberry Two Beta (64-bit)" >> $GITHUB_OUTPUT
            echo "description=RasQberry beta release with latest features (may be unstable)" >> $GITHUB_OUTPUT
          else
            echo "type=dev" >> $GITHUB_OUTPUT
            echo "name=RasQberry Two Dev (64-bit)" >> $GITHUB_OUTPUT
            echo "description=RasQberry development build with cutting-edge features (unstable)" >> $GITHUB_OUTPUT
          fi
          
      - name: Generate RQB-images.json
        run: |
          # Try to fetch existing JSON from gh-pages as base
          echo "Fetching existing RQB-images.json from gh-pages..."
          
          # Attempt to download existing JSON from gh-pages
          if curl -s -f "https://raw.githubusercontent.com/${{ github.repository }}/gh-pages/RQB-images.json" -o existing.json; then
            echo "✓ Found existing JSON on gh-pages, using as base"
            cp existing.json RQB-images.json
          else
            echo "ℹ No existing JSON found on gh-pages, creating fresh base"
            cat > RQB-images.json << 'EOF'
          {
            "imager": {
              "latest_version": "1.8.5",
              "url": "https://www.raspberrypi.com/software/"
            },
            "os_list": []
          }
          EOF
          fi
          
          # Generate the new entry
          VERSION_TYPE="${{ steps.version-type.outputs.type }}"
          cat > new_entry.json << EOF
          {
            "name": "${{ steps.version-type.outputs.name }}",
            "description": "${{ steps.version-type.outputs.description }}",
            "icon": "https://rasqberry.org/Artwork/RasQberry 2 Logo Cube 64x64.png",
            "url": "${{ steps.metadata.outputs.download_url }}",
            "extract_size": ${{ steps.metadata.outputs.extract_size }},
            "extract_sha256": "${{ steps.metadata.outputs.extract_sha256 }}",
            "image_download_size": ${{ steps.metadata.outputs.compressed_size }},
            "release_date": "${{ steps.metadata.outputs.release_date }}",
            "init_format": "systemd",
            "devices": ["pi5-64bit", "pi4-64bit"],
            "website": "https://rasqberry.org"
          }
          EOF
          
          # Use Python to update the JSON (handles JSON parsing properly)
          python3 << 'PYTHON_SCRIPT'
          import json
          import sys
          from datetime import datetime
          
          # Load existing JSON
          with open('RQB-images.json', 'r') as f:
              data = json.load(f)
          
          # Load new entry
          with open('new_entry.json', 'r') as f:
              new_entry = json.load(f)
          
          version_type = "${{ steps.version-type.outputs.type }}"
          print(f"Processing {version_type} version entry...")
          
          # Define mapping of version types to name patterns
          type_patterns = {
              "main": "RasQberry Two (64-bit)",
              "beta": "RasQberry Two Beta (64-bit)", 
              "dev": "RasQberry Two Dev (64-bit)"
          }
          
          # Remove existing entry of the same type (keep only latest per type)
          initial_count = len(data['os_list'])
          data['os_list'] = [entry for entry in data['os_list'] 
                           if entry['name'] != type_patterns.get(version_type, new_entry['name'])]
          removed_count = initial_count - len(data['os_list'])
          
          if removed_count > 0:
              print(f"Removed {removed_count} existing {version_type} entry(ies)")
          
          # Find the right position to insert the new entry
          # Order: main (if exists), beta (if exists), dev (if exists), then others
          insert_position = 0
          priority_order = ["main", "beta", "dev"]
          current_type_priority = priority_order.index(version_type) if version_type in priority_order else 999
          
          for i, entry in enumerate(data['os_list']):
              # Determine the type of this existing entry
              entry_type = None
              for type_name, pattern in type_patterns.items():
                  if entry['name'] == pattern:
                      entry_type = type_name
                      break
              
              if entry_type and entry_type in priority_order:
                  entry_priority = priority_order.index(entry_type)
                  if current_type_priority < entry_priority:
                      insert_position = i
                      break
              else:
                  # Non-RasQberry entry, insert before it
                  insert_position = i
                  break
              insert_position = i + 1
          
          # Insert the new entry at the calculated position
          data['os_list'].insert(insert_position, new_entry)
          print(f"Inserted new {version_type} entry at position {insert_position}")
          
          # Add official Raspberry Pi OS and Custom option if not present
          has_raspios = any("Raspberry Pi OS" in entry['name'] for entry in data['os_list'])
          has_custom = any("Custom" in entry.get('name', '') for entry in data['os_list'])
          
          if not has_raspios:
              raspios_entry = {
                  "name": "Raspberry Pi OS (64-bit)",
                  "description": "A port of Debian Bookworm with the Raspberry Pi Desktop (Recommended)",
                  "icon": "https://downloads.raspberrypi.com/raspios_armhf/Raspberry_Pi_OS_(32-bit).png",
                  "url": "https://downloads.raspberrypi.com/raspios_arm64/images/raspios_arm64-2024-10-28/2024-10-22-raspios-bookworm-arm64.img.xz",
                  "extract_size": 6102712320,
                  "extract_sha256": "88093218a66cf20e8669963902a949c4c23b73309c2fc3331d09fa6ee2134417",
                  "image_download_size": 1238664180,
                  "release_date": "2024-10-22",
                  "init_format": "systemd",
                  "devices": ["pi5-64bit", "pi4-64bit"]
              }
              data['os_list'].append(raspios_entry)
          
          if not has_custom:
              custom_entry = {
                  "name": "Use custom image",
                  "description": "Select a custom .img from your computer",
                  "icon": "https://downloads.raspberrypi.com/imager/icons/folder.png"
              }
              data['os_list'].append(custom_entry)
          
          # Write updated JSON
          with open('RQB-images.json', 'w') as f:
              json.dump(data, f, indent=2)
          
          print(f"Updated RQB-images.json with {version_type} version")
          PYTHON_SCRIPT
          
          # Clean up temporary file
          rm -f new_entry.json
          
      - name: Commit JSON to current branch
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          
          # Pull latest changes to avoid conflicts
          git pull origin ${{ github.ref_name }} || echo "No remote changes to pull"
          
          # Always commit the JSON file to current branch
          git add RQB-images.json
          git commit -m "Generate RQB-images.json for ${{ steps.version-type.outputs.type }} release ${{ steps.metadata.outputs.version_num }}"
          git push origin ${{ github.ref_name }}
          echo "Generated RQB-images.json in current branch"
          
      - name: Upload JSON to gh-pages
        if: ${{ github.event.inputs.publish_json == 'true' }}
        run: |
          echo "Uploading RQB-images.json to gh-pages..."
          
          # Fetch and checkout gh-pages
          git fetch origin gh-pages || echo "No gh-pages branch found"
          if git show-ref --verify --quiet refs/remotes/origin/gh-pages; then
            git checkout gh-pages
            
            # Copy the generated JSON file
            git checkout ${{ github.ref_name }} -- RQB-images.json
            
            # Commit and push to gh-pages
            git add RQB-images.json
            git commit -m "Update RQB-images.json from ${{ github.ref_name }} with ${{ steps.version-type.outputs.type }} release ${{ steps.metadata.outputs.version_num }}"
            git push origin gh-pages
            echo "Successfully uploaded RQB-images.json to gh-pages"
          else
            echo "No gh-pages branch exists, skipping upload"
          fi

